{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wahana Cerdas Chatbot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Package sentence tokenizer\\nnltk.download('punkt') \\n# Package lemmatization\\nnltk.download('wordnet')\\n# Package multilingual wordnet data\\nnltk.download('omw-1.4')\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import nltk\n",
    "import time\n",
    "import re\n",
    "import swifter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Flatten, Dense, GlobalMaxPool1D\n",
    "\n",
    "from urllib import request\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "'''# Package sentence tokenizer\n",
    "nltk.download('punkt') \n",
    "# Package lemmatization\n",
    "nltk.download('wordnet')\n",
    "# Package multilingual wordnet data\n",
    "nltk.download('omw-1.4')'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Data%20Wahana.json', <http.client.HTTPMessage at 0x226507ae6a0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/Handepp/Tugas-Akhir-Chatbot/main/Dataset/Data%20Wahana.json\"\n",
    "request.urlretrieve(url, \"Data%20Wahana.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "with open('Data%20Wahana.json') as content:\n",
    "  data1 = json.load(content)\n",
    "\n",
    "# Mendapatkan semua data ke dalam list\n",
    "tags = [] # data tag\n",
    "inputs = [] # data input atau pattern\n",
    "responses = {} # data respon\n",
    "words = [] # Data kata \n",
    "classes = [] # Data Kelas atau Tag\n",
    "documents = [] # Data Kalimat Dokumen\n",
    "ignore_words = ['?', '!'] # Mengabaikan tanda spesial karakter\n",
    "\n",
    "for intent in data1['intents']:\n",
    "  responses[intent['tag']]=intent['responses']\n",
    "  for lines in intent['patterns']:\n",
    "    inputs.append(lines)\n",
    "    tags.append(intent['tag'])\n",
    "    for pattern in intent['patterns']:\n",
    "      w = nltk.word_tokenize(pattern)\n",
    "      words.extend(w)\n",
    "      documents.append((w, intent['tag']))\n",
    "      # add to our classes list\n",
    "      if intent['tag'] not in classes:\n",
    "        classes.append(intent['tag'])\n",
    "\n",
    "# Konversi data json ke dalam dataframe\n",
    "data = pd.DataFrame({\"patterns\":inputs, \"tags\":tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patterns</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Siapa kamu?</td>\n",
       "      <td>Wardas.siapa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kamu siapa?</td>\n",
       "      <td>Wardas.siapa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ini apa?</td>\n",
       "      <td>Wardas.siapa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kamu apa?</td>\n",
       "      <td>Wardas.siapa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robot apakah kamu?</td>\n",
       "      <td>Wardas.siapa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Beritahu dayamu</td>\n",
       "      <td>wardas.Baterai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Beritahu nilai baterai mu</td>\n",
       "      <td>wardas.Baterai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Berapa lagi baterai yang kamu miliki</td>\n",
       "      <td>wardas.Baterai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Jumlah kapasitas bateraimu</td>\n",
       "      <td>wardas.Baterai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Berapa persen lagi baterai yang kamu punya</td>\n",
       "      <td>wardas.Baterai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       patterns            tags\n",
       "0                                   Siapa kamu?    Wardas.siapa\n",
       "1                                   Kamu siapa?    Wardas.siapa\n",
       "2                                      Ini apa?    Wardas.siapa\n",
       "3                                     Kamu apa?    Wardas.siapa\n",
       "4                            Robot apakah kamu?    Wardas.siapa\n",
       "..                                          ...             ...\n",
       "186                             Beritahu dayamu  wardas.Baterai\n",
       "187                   Beritahu nilai baterai mu  wardas.Baterai\n",
       "188        Berapa lagi baterai yang kamu miliki  wardas.Baterai\n",
       "189                  Jumlah kapasitas bateraimu  wardas.Baterai\n",
       "190  Berapa persen lagi baterai yang kamu punya  wardas.Baterai\n",
       "\n",
       "[191 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cetak data keseluruhan\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wardas.siapa          15\n",
       "wardas.buruk          11\n",
       "wardas.usia           10\n",
       "wardas.hari            8\n",
       "wardas.beban           7\n",
       "wardas.tanggal         7\n",
       "wardas.terimakasih     7\n",
       "wardas.lokasi          7\n",
       "wardas.Baterai         7\n",
       "wardas.insaf           7\n",
       "wardas.sapa            6\n",
       "wardas.fast            6\n",
       "wardas.medium          6\n",
       "wardas.slow            6\n",
       "wardas.jam             6\n",
       "wardas.benar           5\n",
       "wardas.hobby           5\n",
       "wardas.bos             5\n",
       "wardas.bantu           5\n",
       "wardas.berpisah        5\n",
       "wardas.hump            5\n",
       "wardas.ngobrol         5\n",
       "wardas.suhu            5\n",
       "wardas.siap            5\n",
       "wardas.baik            5\n",
       "wardas.asal            5\n",
       "wardas.sore            5\n",
       "wardas.pagi            5\n",
       "wardas.siang           5\n",
       "wardas.malam           5\n",
       "Name: tags, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tags.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 classes ['Wardas.siapa', 'wardas.Baterai', 'wardas.asal', 'wardas.baik', 'wardas.bantu', 'wardas.beban', 'wardas.benar', 'wardas.berpisah', 'wardas.bos', 'wardas.buruk', 'wardas.fast', 'wardas.hari', 'wardas.hobby', 'wardas.hump', 'wardas.insaf', 'wardas.jam', 'wardas.lokasi', 'wardas.malam', 'wardas.medium', 'wardas.ngobrol', 'wardas.pagi', 'wardas.sapa', 'wardas.siang', 'wardas.siap', 'wardas.slow', 'wardas.sore', 'wardas.suhu', 'wardas.tanggal', 'wardas.terimakasih', 'wardas.usia']\n"
     ]
    }
   ],
   "source": [
    "# sort classes\n",
    "classes = sorted(list(set(classes)))\n",
    "print (len(classes), \"classes\", classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def casefolding(text):\n",
    "  text = text.lower()                               # Mengubah teks menjadi lower case\n",
    "  text = re.sub(r'https?://\\S+|www\\.\\S+', '', text) # Menghapus URL\n",
    "  #text = re.sub(r'[-+]?[0-9]+', '', text)           # Menghapus angka\n",
    "  text = re.sub(r'[^\\w\\s]','', text)                # Menghapus karakter tanda baca\n",
    "  text = text.strip()                               # Menghapus whitespaces\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   _id      singkat       hasil\n",
      "0    1         abis       habis\n",
      "1    2       accent     tekanan\n",
      "2    3       accept      terima\n",
      "3    4     accident  kecelakaan\n",
      "4    5  achievement    prestasi\n"
     ]
    }
   ],
   "source": [
    "key= \"https://raw.githubusercontent.com/ksnugroho/klasifikasi-spam-sms/master/data/key_norm.csv\"\n",
    "request.urlretrieve(key, \"key_norm.csv\")\n",
    "key_norm = pd.read_csv('key_norm.csv')\n",
    "print(key_norm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_normalize(text):\n",
    "  text = ' '.join([key_norm[key_norm['singkat'] == word]['hasil'].values[0] if (key_norm['singkat'] == word).any() else word for word in text.split()])\n",
    "  text = str.lower(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# Buat fungsi untuk langkah stemming bahasa Indonesia\n",
    "def stemming(text):\n",
    "  text = stemmer.stem(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing_process(text):\n",
    "  text = casefolding(text)\n",
    "  text = text_normalize(text)\n",
    "  text = stemming(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0344c8ff5ab84f658dc5e18f93eef5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.44 s\n",
      "Wall time: 3.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['patterns'] = data['patterns'].swifter.apply(text_preprocessing_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patterns</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>siapa kamu</td>\n",
       "      <td>Wardas.siapa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kamu siapa</td>\n",
       "      <td>Wardas.siapa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ini apa</td>\n",
       "      <td>Wardas.siapa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kamu apa</td>\n",
       "      <td>Wardas.siapa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>robot apakah kamu</td>\n",
       "      <td>Wardas.siapa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>beritahu daya</td>\n",
       "      <td>wardas.Baterai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>beritahu nilai baterai mu</td>\n",
       "      <td>wardas.Baterai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>berapa lagi baterai yang kamu milik</td>\n",
       "      <td>wardas.Baterai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>jumlah kapasitas baterai</td>\n",
       "      <td>wardas.Baterai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>berapa persen lagi baterai yang kamu punya</td>\n",
       "      <td>wardas.Baterai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       patterns            tags\n",
       "0                                    siapa kamu    Wardas.siapa\n",
       "1                                    kamu siapa    Wardas.siapa\n",
       "2                                       ini apa    Wardas.siapa\n",
       "3                                      kamu apa    Wardas.siapa\n",
       "4                             robot apakah kamu    Wardas.siapa\n",
       "..                                          ...             ...\n",
       "186                               beritahu daya  wardas.Baterai\n",
       "187                   beritahu nilai baterai mu  wardas.Baterai\n",
       "188         berapa lagi baterai yang kamu milik  wardas.Baterai\n",
       "189                    jumlah kapasitas baterai  wardas.Baterai\n",
       "190  berapa persen lagi baterai yang kamu punya  wardas.Baterai\n",
       "\n",
       "[191 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Ada banyak cara untuk menentukan max_length\n",
    "Intuisinya adalah kita tidak ingin memotong kalimat, atau terlalu banyak menambahkan padding (komputasi lebih lama)\n",
    "Contoh ini, max_lenght ditentukan dari distribusi token pada dataset \n",
    "'''\n",
    "token_lens = []\n",
    "\n",
    "for text in data['patterns']:\n",
    "    tokens = text.split()\n",
    "    token_lens.append(len(tokens))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(token_lens, kde=True, stat='density', linewidth=0)\n",
    "plt.xlim([0, 10]);\n",
    "plt.xlabel('Token count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 1],\n",
       " [1, 20],\n",
       " [2, 6],\n",
       " [1, 6],\n",
       " [9, 24, 1],\n",
       " [9, 6, 2],\n",
       " [6, 1, 2],\n",
       " [93, 9, 2, 43, 6],\n",
       " [1, 53, 43, 6],\n",
       " [1, 54, 6],\n",
       " [94, 44, 1],\n",
       " [3, 54, 43, 6],\n",
       " [62, 45, 63],\n",
       " [64, 45, 63],\n",
       " [46, 45, 44],\n",
       " [65],\n",
       " [4, 65],\n",
       " [25, 1, 47],\n",
       " [11, 7, 25, 1, 55],\n",
       " [95, 66],\n",
       " [66],\n",
       " [47, 25],\n",
       " [9, 2, 48, 25],\n",
       " [25, 1, 48],\n",
       " [25, 48],\n",
       " [9, 67],\n",
       " [1, 2, 67],\n",
       " [1, 32, 53],\n",
       " [1, 32, 12, 26, 68, 17, 7, 69],\n",
       " [1, 96, 70],\n",
       " [1, 2, 32, 12, 26, 13, 49],\n",
       " [97, 1, 26, 13, 33],\n",
       " [1, 2, 33],\n",
       " [98, 1, 2, 33],\n",
       " [1, 99, 13, 33],\n",
       " [1, 26, 13, 33],\n",
       " [71, 1, 8, 50, 72],\n",
       " [18, 44, 100, 50, 53],\n",
       " [101, 43, 8, 50, 72],\n",
       " [1, 73, 74],\n",
       " [102, 8, 50, 18],\n",
       " [71, 1, 12, 74, 13, 18, 27],\n",
       " [1, 73, 8, 70],\n",
       " [20, 103],\n",
       " [20, 17, 75],\n",
       " [56, 54, 20],\n",
       " [1, 75, 104, 20],\n",
       " [76, 20, 1],\n",
       " [3, 28, 7, 10],\n",
       " [105, 1, 28, 106],\n",
       " [28, 7, 10],\n",
       " [7, 57, 28],\n",
       " [28, 7, 3],\n",
       " [24, 1, 56, 34],\n",
       " [6, 34],\n",
       " [107, 13, 34],\n",
       " [64, 45, 34],\n",
       " [11, 7, 34],\n",
       " [24, 1, 51],\n",
       " [24, 9, 77, 51],\n",
       " [24, 1, 77, 51],\n",
       " [108],\n",
       " [51, 44],\n",
       " [109, 78],\n",
       " [1, 78, 110, 14],\n",
       " [14, 1, 48],\n",
       " [14, 1, 47],\n",
       " [9, 2, 47, 14],\n",
       " [1, 49],\n",
       " [1, 62, 17, 49],\n",
       " [1, 111, 112, 26, 68, 7],\n",
       " [1, 113],\n",
       " [1, 26, 13, 49],\n",
       " [58, 46, 13],\n",
       " [58, 114],\n",
       " [46, 13, 7],\n",
       " [58, 46],\n",
       " [115, 116],\n",
       " [35, 3],\n",
       " [117],\n",
       " [118],\n",
       " [119],\n",
       " [120, 3],\n",
       " [121, 3],\n",
       " [15, 36, 3],\n",
       " [36],\n",
       " [15, 36],\n",
       " [36, 3],\n",
       " [35, 36, 3],\n",
       " [15, 37, 3],\n",
       " [37],\n",
       " [15, 37],\n",
       " [37, 3],\n",
       " [35, 37, 3],\n",
       " [15, 38, 3],\n",
       " [38],\n",
       " [15, 38],\n",
       " [38, 3],\n",
       " [35, 38, 3],\n",
       " [15, 39, 3],\n",
       " [39],\n",
       " [15, 39],\n",
       " [39, 3],\n",
       " [35, 39, 3],\n",
       " [122, 18, 32, 79],\n",
       " [7, 18],\n",
       " [18, 18],\n",
       " [32, 55, 79],\n",
       " [123, 18],\n",
       " [1, 55, 14],\n",
       " [9, 1, 14],\n",
       " [14, 1],\n",
       " [124, 80, 1],\n",
       " [81, 80, 82],\n",
       " [125, 14],\n",
       " [27, 14, 1, 9],\n",
       " [4, 40, 29, 2],\n",
       " [40, 29, 2],\n",
       " [11, 40, 83, 29, 2],\n",
       " [40, 19, 2],\n",
       " [7, 57, 40, 19, 2],\n",
       " [4, 41, 29, 2],\n",
       " [41, 29, 2],\n",
       " [11, 41, 83, 29, 2],\n",
       " [41, 19, 2],\n",
       " [7, 57, 41, 19, 2],\n",
       " [59],\n",
       " [84, 85],\n",
       " [59, 3],\n",
       " [59],\n",
       " [126, 1],\n",
       " [127],\n",
       " [84, 85, 86, 128, 28],\n",
       " [15, 129],\n",
       " [130],\n",
       " [69, 131, 27],\n",
       " [132, 87, 133],\n",
       " [134, 87],\n",
       " [60, 4, 10],\n",
       " [11, 7, 88, 10],\n",
       " [135, 4, 10],\n",
       " [88, 19, 2],\n",
       " [60, 19, 2],\n",
       " [19, 2, 60, 4],\n",
       " [16, 6, 10],\n",
       " [16, 2, 16, 6],\n",
       " [16, 6],\n",
       " [10, 16, 6],\n",
       " [16, 2],\n",
       " [11, 16, 6, 2],\n",
       " [16, 24, 2],\n",
       " [],\n",
       " [21, 4, 10],\n",
       " [10, 21, 4],\n",
       " [11, 21, 4, 10],\n",
       " [21, 4],\n",
       " [21, 19, 2],\n",
       " [7, 136, 21, 16, 2],\n",
       " [21, 4, 2],\n",
       " [4, 22, 17, 12, 23, 9],\n",
       " [9, 2, 12, 23, 22, 89, 4],\n",
       " [12, 23, 22, 4],\n",
       " [137, 22, 17, 12, 23],\n",
       " [138, 89, 23, 4, 22],\n",
       " [90, 22, 17, 12, 23],\n",
       " [1, 12, 23, 4, 86, 22],\n",
       " [30, 5, 8, 31],\n",
       " [31, 5],\n",
       " [8, 31],\n",
       " [31, 61],\n",
       " [5, 31],\n",
       " [30, 8, 31],\n",
       " [30, 5, 8, 52],\n",
       " [139, 5],\n",
       " [8, 140],\n",
       " [52, 61],\n",
       " [5, 52],\n",
       " [30, 8, 52],\n",
       " [30, 5, 8, 5],\n",
       " [5, 5],\n",
       " [8, 5],\n",
       " [5, 61],\n",
       " [5, 5],\n",
       " [30, 8, 5],\n",
       " [81, 91],\n",
       " [42, 4, 92, 27],\n",
       " [11, 91],\n",
       " [11, 141, 42, 82],\n",
       " [4, 27, 42, 17, 1, 56],\n",
       " [90, 142, 42],\n",
       " [4, 92, 27, 42, 17, 1, 76]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the data (Tokenisasi Data)\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(data['patterns'])\n",
    "train = tokenizer.texts_to_sequences(data['patterns'])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "NUM_WORDS = 100       # Frekuensi kemunculan kata. Hanya num_words-1 yang akan disimpan pada dictionary. Berarti kata dengan kemunculan <=num_words tidak digunakan.\n",
    "OOV_TOKEN = '<unk>'   # Token khusus untuk mengganti kata yang tidak terdaftar dalam dictionary.\n",
    "\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=OOV_TOKEN, lower=True, split=' ')\n",
    "tokenizer.fit_on_texts(data['patterns'])\n",
    "\n",
    "# Tambahkan token padding untuk menyamakan ukuran dimensi embedding layer\n",
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'\n",
    "\n",
    "WV_DICTIONARY = tokenizer.word_index\n",
    "\n",
    "WV_DICTIONARY_SIZE = len(WV_DICTIONARY)\n",
    "print(WV_DICTIONARY_SIZE) # Lihat kata unik pada dictionary yang dihasilkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 1,\n",
       " 'kamu': 2,\n",
       " 'ini': 3,\n",
       " 'wardas': 4,\n",
       " 'berapa': 5,\n",
       " 'cepat': 6,\n",
       " 'apa': 7,\n",
       " 'saya': 8,\n",
       " 'jadi': 9,\n",
       " 'robot': 10,\n",
       " 'sekarang': 11,\n",
       " 'beritahu': 12,\n",
       " 'dapat': 13,\n",
       " 'dengan': 14,\n",
       " 'mana': 15,\n",
       " 'selamat': 16,\n",
       " 'hari': 17,\n",
       " 'yang': 18,\n",
       " 'baik': 19,\n",
       " 'saat': 20,\n",
       " 'siapa': 21,\n",
       " 'tanggal': 22,\n",
       " 'bebanberat': 23,\n",
       " 'bawa': 24,\n",
       " 'apakah': 25,\n",
       " 'kapan': 26,\n",
       " 'jawab': 27,\n",
       " 'lagi': 28,\n",
       " 'bantu': 29,\n",
       " 'ruang': 30,\n",
       " 'ubah': 31,\n",
       " 'lambat': 32,\n",
       " 'tidak': 33,\n",
       " 'salah': 34,\n",
       " 'hobi': 35,\n",
       " 'halo': 36,\n",
       " 'siang': 37,\n",
       " 'pagi': 38,\n",
       " 'sore': 39,\n",
       " 'malam': 40,\n",
       " 'suhu': 41,\n",
       " 'lembap': 42,\n",
       " 'baterai': 43,\n",
       " 'untuk': 44,\n",
       " 'diri': 45,\n",
       " 'tentang': 46,\n",
       " 'bicara': 47,\n",
       " 'cipta': 48,\n",
       " 'buat': 49,\n",
       " 'benar': 50,\n",
       " 'lebih': 51,\n",
       " 'siap': 52,\n",
       " 'sedangmedium': 53,\n",
       " 'guna': 54,\n",
       " 'itu': 55,\n",
       " 'ada': 56,\n",
       " 'milik': 57,\n",
       " 'butuh': 58,\n",
       " 'ayo': 59,\n",
       " 'terimakasih': 60,\n",
       " 'jam': 61,\n",
       " 'saja': 62,\n",
       " 'kata': 63,\n",
       " 'anda': 64,\n",
       " 'cerita': 65,\n",
       " 'umur': 66,\n",
       " 'usia': 67,\n",
       " 'bodoh': 68,\n",
       " 'tanya': 69,\n",
       " 'sampai': 70,\n",
       " 'pintar': 71,\n",
       " 'moga': 72,\n",
       " 'pintarbaik': 73,\n",
       " 'harus': 74,\n",
       " 'ajar': 75,\n",
       " 'kembang': 76,\n",
       " 'punya': 77,\n",
       " 'sudah': 78,\n",
       " 'asal': 79,\n",
       " 'masalah': 80,\n",
       " 'lokasi': 81,\n",
       " 'tunjuk': 82,\n",
       " 'mu': 83,\n",
       " 'pada': 84,\n",
       " 'terima': 85,\n",
       " 'kasih': 86,\n",
       " 'banyak': 87,\n",
       " 'dulu': 88,\n",
       " 'waktu': 89,\n",
       " 'hingga': 90,\n",
       " 'jumlah': 91,\n",
       " 'daya': 92,\n",
       " 'persen': 93,\n",
       " 'fungsi': 94,\n",
       " 'jelas': 95,\n",
       " 'beritahukan': 96,\n",
       " 'tidakkurang': 97,\n",
       " 'kenapa': 98,\n",
       " 'respon': 99,\n",
       " 'merespon': 100,\n",
       " 'agar': 101,\n",
       " 'coba': 102,\n",
       " 'rubah': 103,\n",
       " 'pemilikmupengembangmubosmu': 104,\n",
       " 'oleh': 105,\n",
       " 'bisa': 106,\n",
       " 'ku': 107,\n",
       " 'bagaimana': 108,\n",
       " 'ready': 109,\n",
       " 'darimana': 110,\n",
       " 'dari': 111,\n",
       " 'benarpintar': 112,\n",
       " 'dalam': 113,\n",
       " 'hebat': 114,\n",
       " 'obrol': 115,\n",
       " 'ngobrol': 116,\n",
       " 'yu': 117,\n",
       " 'haiiii': 118,\n",
       " 'haloooo': 119,\n",
       " 'hello': 120,\n",
       " 'hai': 121,\n",
       " 'yoo': 122,\n",
       " 'kabar': 123,\n",
       " 'sangat': 124,\n",
       " 'ikan': 125,\n",
       " 'sedang': 126,\n",
       " 'thank': 127,\n",
       " 'tengkyu': 128,\n",
       " 'atas': 129,\n",
       " 'tinggal': 130,\n",
       " 'dadah': 131,\n",
       " 'jumpa': 132,\n",
       " 'pergi': 133,\n",
       " 'ya': 134,\n",
       " 'cabut': 135,\n",
       " 'pukul': 136,\n",
       " 'mau': 137,\n",
       " 'maksimal': 138,\n",
       " 'kuat': 139,\n",
       " 'sedangmediumkan': 140,\n",
       " 'sedangmediumlah': 141,\n",
       " 'nilai': 142,\n",
       " 'kapasitas': 143,\n",
       " '<pad>': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WV_DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proses mengubah token hasil tokenisasi menjadi urutan bilangan int berdasarkan index dictionary.\n",
    "data_seq = tokenizer.texts_to_sequences(data['patterns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING = 'post'        # Berikan padding untuk setiap sequences. Terdapat dua pilihan dalam melakukan padding 'pre' or 'post'.\n",
    "TRUNCATING = 'post'     # Menghapus token dari sequences yang lebih besar dari max_lenght. Terdapat dua pilihan dalam melakukan truncanting 'pre' or 'post'.\n",
    "\n",
    "data_pad = pad_sequences(data_seq, maxlen=MAX_SEQ_LENGTH, padding=PADDING, truncating=TRUNCATING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 29 29 29 29 29 29 29 29 29\n",
      " 29  9  9  9  9  9  9  9  9  9  9  9 14 14 14 14 14 14 14  8  8  8  8  8\n",
      "  4  4  4  4  4 12 12 12 12 12 23 23 23 23 23  2  2  2  2  2  6  6  6  6\n",
      "  6 19 19 19 19 19 21 21 21 21 21 21 22 22 22 22 22 20 20 20 20 20 25 25\n",
      " 25 25 25 17 17 17 17 17  3  3  3  3  3 16 16 16 16 16 16 16 26 26 26 26\n",
      " 26 13 13 13 13 13 28 28 28 28 28 28 28  7  7  7  7  7 15 15 15 15 15 15\n",
      " 11 11 11 11 11 11 11 11 27 27 27 27 27 27 27  5  5  5  5  5  5  5 24 24\n",
      " 24 24 24 24 18 18 18 18 18 18 10 10 10 10 10 10  1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "# Encoding the outputs \n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(data['tags'])\n",
    "print(y) #Label Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((152, 9), (39, 9), (152,), (39,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split arrays or matrices into random train and test subsets.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_pad, y, test_size=0.20)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\n",
    "'''\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "\n",
    "model_LSTM = Sequential()\n",
    "model_LSTM.add(Embedding(                                           # Buat embedding layer yang menerima panjang dictionary hasil Tokenisasi\n",
    "    input_dim = WV_DICTIONARY_SIZE,\n",
    "    input_length = MAX_SEQ_LENGTH,\n",
    "    output_dim = 100))      \n",
    "model_LSTM.add(LSTM(100))                                            # Tambahkan satu layer LSTM\n",
    "model_LSTM.add(Dropout(0.5))                             \n",
    "model_LSTM.add(Dense(30, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 9, 100)            14400     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                3030      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 97,830\n",
      "Trainable params: 97,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_LSTM.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "10/10 [==============================] - 4s 50ms/step - loss: 3.4016 - accuracy: 0.0132 - val_loss: 3.4035 - val_accuracy: 0.0769\n",
      "Epoch 2/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3.3923 - accuracy: 0.0526 - val_loss: 3.4009 - val_accuracy: 0.1026\n",
      "Epoch 3/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3.3763 - accuracy: 0.0658 - val_loss: 3.4008 - val_accuracy: 0.1026\n",
      "Epoch 4/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3.3637 - accuracy: 0.0855 - val_loss: 3.3961 - val_accuracy: 0.1026\n",
      "Epoch 5/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3.3381 - accuracy: 0.0855 - val_loss: 3.3917 - val_accuracy: 0.1026\n",
      "Epoch 6/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3.3150 - accuracy: 0.0855 - val_loss: 3.3801 - val_accuracy: 0.1026\n",
      "Epoch 7/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3.2510 - accuracy: 0.0921 - val_loss: 3.3172 - val_accuracy: 0.1282\n",
      "Epoch 8/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3.0982 - accuracy: 0.1711 - val_loss: 3.1976 - val_accuracy: 0.1282\n",
      "Epoch 9/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 2.8350 - accuracy: 0.1908 - val_loss: 3.0666 - val_accuracy: 0.2051\n",
      "Epoch 10/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 2.5787 - accuracy: 0.2237 - val_loss: 2.9402 - val_accuracy: 0.2564\n",
      "Epoch 11/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 2.4423 - accuracy: 0.2368 - val_loss: 2.8399 - val_accuracy: 0.2821\n",
      "Epoch 12/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 2.1984 - accuracy: 0.3158 - val_loss: 2.6950 - val_accuracy: 0.2821\n",
      "Epoch 13/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2.0114 - accuracy: 0.3421 - val_loss: 2.6443 - val_accuracy: 0.2564\n",
      "Epoch 14/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.8656 - accuracy: 0.3882 - val_loss: 2.6464 - val_accuracy: 0.2821\n",
      "Epoch 15/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.6781 - accuracy: 0.4605 - val_loss: 2.5775 - val_accuracy: 0.3077\n",
      "Epoch 16/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.4819 - accuracy: 0.5658 - val_loss: 2.4960 - val_accuracy: 0.3333\n",
      "Epoch 17/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.3197 - accuracy: 0.6447 - val_loss: 2.4228 - val_accuracy: 0.3333\n",
      "Epoch 18/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.2634 - accuracy: 0.5921 - val_loss: 2.5116 - val_accuracy: 0.3846\n",
      "Epoch 19/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.1720 - accuracy: 0.6250 - val_loss: 2.2953 - val_accuracy: 0.3846\n",
      "Epoch 20/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0157 - accuracy: 0.6908 - val_loss: 2.5009 - val_accuracy: 0.4103\n",
      "Epoch 21/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9978 - accuracy: 0.7171 - val_loss: 2.1204 - val_accuracy: 0.3846\n",
      "Epoch 22/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.8305 - accuracy: 0.7632 - val_loss: 2.1201 - val_accuracy: 0.4359\n",
      "Epoch 23/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7694 - accuracy: 0.7829 - val_loss: 1.9880 - val_accuracy: 0.5385\n",
      "Epoch 24/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6760 - accuracy: 0.8289 - val_loss: 1.9412 - val_accuracy: 0.5385\n",
      "Epoch 25/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5850 - accuracy: 0.8553 - val_loss: 1.9693 - val_accuracy: 0.5128\n",
      "Epoch 26/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5592 - accuracy: 0.8750 - val_loss: 1.9160 - val_accuracy: 0.5897\n",
      "Epoch 27/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4678 - accuracy: 0.8750 - val_loss: 2.0001 - val_accuracy: 0.5897\n",
      "Epoch 28/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4147 - accuracy: 0.8947 - val_loss: 2.0114 - val_accuracy: 0.5641\n",
      "Epoch 29/400\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5285 - accuracy: 0.8618 - val_loss: 1.9003 - val_accuracy: 0.5641\n",
      "Epoch 30/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3953 - accuracy: 0.9211 - val_loss: 1.9009 - val_accuracy: 0.6410\n",
      "Epoch 31/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3840 - accuracy: 0.9079 - val_loss: 1.8153 - val_accuracy: 0.5897\n",
      "Epoch 32/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3328 - accuracy: 0.9211 - val_loss: 1.8095 - val_accuracy: 0.6410\n",
      "Epoch 33/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2795 - accuracy: 0.9342 - val_loss: 1.8139 - val_accuracy: 0.6154\n",
      "Epoch 34/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2651 - accuracy: 0.9276 - val_loss: 1.7985 - val_accuracy: 0.5897\n",
      "Epoch 35/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2794 - accuracy: 0.9539 - val_loss: 1.8578 - val_accuracy: 0.6154\n",
      "Epoch 36/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2779 - accuracy: 0.9474 - val_loss: 1.9220 - val_accuracy: 0.5641\n",
      "Epoch 37/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2540 - accuracy: 0.9539 - val_loss: 1.8508 - val_accuracy: 0.6410\n",
      "Epoch 38/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2099 - accuracy: 0.9737 - val_loss: 1.7636 - val_accuracy: 0.6410\n",
      "Epoch 39/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2365 - accuracy: 0.9474 - val_loss: 1.8463 - val_accuracy: 0.6410\n",
      "Epoch 40/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2741 - accuracy: 0.9539 - val_loss: 1.8357 - val_accuracy: 0.6667\n",
      "Epoch 41/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2487 - accuracy: 0.9474 - val_loss: 1.7757 - val_accuracy: 0.6154\n",
      "Epoch 42/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1909 - accuracy: 0.9605 - val_loss: 1.7589 - val_accuracy: 0.6154\n",
      "Epoch 43/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2530 - accuracy: 0.9605 - val_loss: 1.7305 - val_accuracy: 0.6667\n",
      "Epoch 44/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1839 - accuracy: 0.9671 - val_loss: 1.7043 - val_accuracy: 0.6410\n",
      "Epoch 45/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1726 - accuracy: 0.9605 - val_loss: 1.7543 - val_accuracy: 0.6667\n",
      "Epoch 46/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1671 - accuracy: 0.9803 - val_loss: 1.7748 - val_accuracy: 0.6667\n",
      "Epoch 47/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1732 - accuracy: 0.9737 - val_loss: 1.7338 - val_accuracy: 0.6667\n",
      "Epoch 48/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1437 - accuracy: 0.9737 - val_loss: 1.7422 - val_accuracy: 0.6667\n",
      "Epoch 49/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1514 - accuracy: 0.9803 - val_loss: 1.8067 - val_accuracy: 0.6667\n",
      "Epoch 50/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1386 - accuracy: 0.9803 - val_loss: 1.7821 - val_accuracy: 0.6667\n",
      "Epoch 51/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1504 - accuracy: 0.9671 - val_loss: 1.7766 - val_accuracy: 0.6667\n",
      "Epoch 52/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1453 - accuracy: 0.9737 - val_loss: 1.8195 - val_accuracy: 0.6667\n",
      "Epoch 53/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1510 - accuracy: 0.9803 - val_loss: 1.8498 - val_accuracy: 0.6667\n",
      "Epoch 54/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1305 - accuracy: 0.9737 - val_loss: 1.7907 - val_accuracy: 0.6923\n",
      "Epoch 55/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1222 - accuracy: 0.9737 - val_loss: 1.7916 - val_accuracy: 0.6667\n",
      "Epoch 56/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1201 - accuracy: 0.9737 - val_loss: 1.8226 - val_accuracy: 0.6410\n",
      "Epoch 57/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1237 - accuracy: 0.9737 - val_loss: 1.8467 - val_accuracy: 0.6410\n",
      "Epoch 58/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1190 - accuracy: 0.9803 - val_loss: 1.7653 - val_accuracy: 0.6667\n",
      "Epoch 59/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1199 - accuracy: 0.9737 - val_loss: 1.7520 - val_accuracy: 0.6667\n",
      "Epoch 60/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1269 - accuracy: 0.9671 - val_loss: 1.8320 - val_accuracy: 0.6410\n",
      "Epoch 61/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1198 - accuracy: 0.9803 - val_loss: 1.8342 - val_accuracy: 0.6667\n",
      "Epoch 62/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1347 - accuracy: 0.9803 - val_loss: 1.8121 - val_accuracy: 0.6667\n",
      "Epoch 63/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0987 - accuracy: 0.9803 - val_loss: 1.7833 - val_accuracy: 0.6667\n",
      "Epoch 64/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1480 - accuracy: 0.9671 - val_loss: 1.7144 - val_accuracy: 0.6410\n",
      "Epoch 65/400\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1320 - accuracy: 0.9605 - val_loss: 1.8982 - val_accuracy: 0.6154\n",
      "Epoch 66/400\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1234 - accuracy: 0.9671 - val_loss: 1.9463 - val_accuracy: 0.6410\n",
      "Epoch 67/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1169 - accuracy: 0.9803 - val_loss: 1.8520 - val_accuracy: 0.6154\n",
      "Epoch 68/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0981 - accuracy: 0.9803 - val_loss: 1.8502 - val_accuracy: 0.6154\n",
      "Epoch 69/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1170 - accuracy: 0.9671 - val_loss: 1.8457 - val_accuracy: 0.6154\n",
      "Epoch 70/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0963 - accuracy: 0.9803 - val_loss: 1.8422 - val_accuracy: 0.6154\n",
      "Epoch 71/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0925 - accuracy: 0.9803 - val_loss: 1.8729 - val_accuracy: 0.6410\n",
      "Epoch 72/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1148 - accuracy: 0.9671 - val_loss: 1.8326 - val_accuracy: 0.6410\n",
      "Epoch 73/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0884 - accuracy: 0.9803 - val_loss: 1.8030 - val_accuracy: 0.6410\n",
      "Epoch 74/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1120 - accuracy: 0.9803 - val_loss: 1.7657 - val_accuracy: 0.6410\n",
      "Epoch 75/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1250 - accuracy: 0.9737 - val_loss: 1.8061 - val_accuracy: 0.6410\n",
      "Epoch 76/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0857 - accuracy: 0.9737 - val_loss: 1.8125 - val_accuracy: 0.6410\n",
      "Epoch 77/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1064 - accuracy: 0.9803 - val_loss: 1.7989 - val_accuracy: 0.6410\n",
      "Epoch 78/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0966 - accuracy: 0.9803 - val_loss: 1.7953 - val_accuracy: 0.6410\n",
      "Epoch 79/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0982 - accuracy: 0.9671 - val_loss: 1.8527 - val_accuracy: 0.6410\n",
      "Epoch 80/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1070 - accuracy: 0.9803 - val_loss: 1.8223 - val_accuracy: 0.6410\n",
      "Epoch 81/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0742 - accuracy: 0.9671 - val_loss: 1.8719 - val_accuracy: 0.6410\n",
      "Epoch 82/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0738 - accuracy: 0.9737 - val_loss: 1.8766 - val_accuracy: 0.6410\n",
      "Epoch 83/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0890 - accuracy: 0.9803 - val_loss: 1.8815 - val_accuracy: 0.6410\n",
      "Epoch 84/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0709 - accuracy: 0.9868 - val_loss: 1.8704 - val_accuracy: 0.6410\n",
      "Epoch 85/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1026 - accuracy: 0.9737 - val_loss: 1.8294 - val_accuracy: 0.6410\n",
      "Epoch 86/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0800 - accuracy: 0.9803 - val_loss: 1.8289 - val_accuracy: 0.6410\n",
      "Epoch 87/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.9737 - val_loss: 1.8293 - val_accuracy: 0.6410\n",
      "Epoch 88/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0740 - accuracy: 0.9868 - val_loss: 1.8510 - val_accuracy: 0.6410\n",
      "Epoch 89/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0569 - accuracy: 0.9737 - val_loss: 1.8996 - val_accuracy: 0.6410\n",
      "Epoch 90/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0700 - accuracy: 0.9737 - val_loss: 1.9300 - val_accuracy: 0.6154\n",
      "Epoch 91/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0858 - accuracy: 0.9737 - val_loss: 1.9307 - val_accuracy: 0.6154\n",
      "Epoch 92/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0951 - accuracy: 0.9737 - val_loss: 1.9184 - val_accuracy: 0.6154\n",
      "Epoch 93/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0780 - accuracy: 0.9605 - val_loss: 1.9100 - val_accuracy: 0.6154\n",
      "Epoch 94/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0722 - accuracy: 0.9868 - val_loss: 1.9301 - val_accuracy: 0.6154\n",
      "Epoch 95/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0897 - accuracy: 0.9671 - val_loss: 1.9109 - val_accuracy: 0.6154\n",
      "Epoch 96/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0731 - accuracy: 0.9868 - val_loss: 1.8747 - val_accuracy: 0.6410\n",
      "Epoch 97/400\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0746 - accuracy: 0.9803 - val_loss: 1.8983 - val_accuracy: 0.6410\n",
      "Epoch 98/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0654 - accuracy: 0.9803 - val_loss: 1.8920 - val_accuracy: 0.6410\n",
      "Epoch 99/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0832 - accuracy: 0.9671 - val_loss: 1.9287 - val_accuracy: 0.6410\n",
      "Epoch 100/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0696 - accuracy: 0.9671 - val_loss: 1.9340 - val_accuracy: 0.6410\n",
      "Epoch 101/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0765 - accuracy: 0.9737 - val_loss: 1.8835 - val_accuracy: 0.6410\n",
      "Epoch 102/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0923 - accuracy: 0.9737 - val_loss: 1.8524 - val_accuracy: 0.6667\n",
      "Epoch 103/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0693 - accuracy: 0.9803 - val_loss: 1.8359 - val_accuracy: 0.6667\n",
      "Epoch 104/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0955 - accuracy: 0.9803 - val_loss: 1.8555 - val_accuracy: 0.6410\n",
      "Epoch 105/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1016 - accuracy: 0.9605 - val_loss: 1.8808 - val_accuracy: 0.6410\n",
      "Epoch 106/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0632 - accuracy: 0.9803 - val_loss: 1.8997 - val_accuracy: 0.6410\n",
      "Epoch 107/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0910 - accuracy: 0.9737 - val_loss: 1.9146 - val_accuracy: 0.6410\n",
      "Epoch 108/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0737 - accuracy: 0.9737 - val_loss: 1.9116 - val_accuracy: 0.6410\n",
      "Epoch 109/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0970 - accuracy: 0.9803 - val_loss: 1.9145 - val_accuracy: 0.6410\n",
      "Epoch 110/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0655 - accuracy: 0.9803 - val_loss: 1.8945 - val_accuracy: 0.6667\n",
      "Epoch 111/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0781 - accuracy: 0.9671 - val_loss: 1.9402 - val_accuracy: 0.6410\n",
      "Epoch 112/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0595 - accuracy: 0.9737 - val_loss: 1.9714 - val_accuracy: 0.6410\n",
      "Epoch 113/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0632 - accuracy: 0.9803 - val_loss: 1.9759 - val_accuracy: 0.6410\n",
      "Epoch 114/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0842 - accuracy: 0.9737 - val_loss: 1.9839 - val_accuracy: 0.6410\n",
      "Epoch 115/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0715 - accuracy: 0.9803 - val_loss: 1.9620 - val_accuracy: 0.6410\n",
      "Epoch 116/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0616 - accuracy: 0.9737 - val_loss: 1.9323 - val_accuracy: 0.6410\n",
      "Epoch 117/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0754 - accuracy: 0.9737 - val_loss: 1.9253 - val_accuracy: 0.6410\n",
      "Epoch 118/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0954 - accuracy: 0.9737 - val_loss: 1.9538 - val_accuracy: 0.6410\n",
      "Epoch 119/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0855 - accuracy: 0.9671 - val_loss: 1.9750 - val_accuracy: 0.6410\n",
      "Epoch 120/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0869 - accuracy: 0.9737 - val_loss: 1.9706 - val_accuracy: 0.6410\n",
      "Epoch 121/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0704 - accuracy: 0.9737 - val_loss: 1.9529 - val_accuracy: 0.6667\n",
      "Epoch 122/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0694 - accuracy: 0.9737 - val_loss: 1.9386 - val_accuracy: 0.6667\n",
      "Epoch 123/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1000 - accuracy: 0.9737 - val_loss: 1.9769 - val_accuracy: 0.6667\n",
      "Epoch 124/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0811 - accuracy: 0.9671 - val_loss: 1.9910 - val_accuracy: 0.6410\n",
      "Epoch 125/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0729 - accuracy: 0.9671 - val_loss: 1.9634 - val_accuracy: 0.6410\n",
      "Epoch 126/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0865 - accuracy: 0.9737 - val_loss: 1.9642 - val_accuracy: 0.6410\n",
      "Epoch 127/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0730 - accuracy: 0.9737 - val_loss: 1.9560 - val_accuracy: 0.6410\n",
      "Epoch 128/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0559 - accuracy: 0.9868 - val_loss: 1.9342 - val_accuracy: 0.6410\n",
      "Epoch 129/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0688 - accuracy: 0.9671 - val_loss: 1.9278 - val_accuracy: 0.6410\n",
      "Epoch 130/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0717 - accuracy: 0.9671 - val_loss: 1.9240 - val_accuracy: 0.6410\n",
      "Epoch 131/400\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0513 - accuracy: 0.9868 - val_loss: 1.9317 - val_accuracy: 0.6410\n",
      "Epoch 132/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0728 - accuracy: 0.9803 - val_loss: 1.9422 - val_accuracy: 0.6410\n",
      "Epoch 133/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0587 - accuracy: 0.9737 - val_loss: 1.9737 - val_accuracy: 0.6410\n",
      "Epoch 134/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0659 - accuracy: 0.9737 - val_loss: 1.9798 - val_accuracy: 0.6410\n",
      "Epoch 135/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0848 - accuracy: 0.9737 - val_loss: 1.9854 - val_accuracy: 0.6410\n",
      "Epoch 136/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0967 - accuracy: 0.9803 - val_loss: 1.9868 - val_accuracy: 0.6410\n",
      "Epoch 137/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0767 - accuracy: 0.9803 - val_loss: 1.9961 - val_accuracy: 0.6410\n",
      "Epoch 138/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0559 - accuracy: 0.9803 - val_loss: 1.9744 - val_accuracy: 0.6410\n",
      "Epoch 139/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0752 - accuracy: 0.9605 - val_loss: 1.9908 - val_accuracy: 0.6410\n",
      "Epoch 140/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0845 - accuracy: 0.9737 - val_loss: 1.9822 - val_accuracy: 0.6410\n",
      "Epoch 141/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0750 - accuracy: 0.9803 - val_loss: 1.9724 - val_accuracy: 0.6410\n",
      "Epoch 142/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0677 - accuracy: 0.9737 - val_loss: 1.9684 - val_accuracy: 0.6410\n",
      "Epoch 143/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0786 - accuracy: 0.9671 - val_loss: 1.9731 - val_accuracy: 0.6410\n",
      "Epoch 144/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0826 - accuracy: 0.9737 - val_loss: 2.0317 - val_accuracy: 0.6410\n",
      "Epoch 145/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0755 - accuracy: 0.9737 - val_loss: 2.0263 - val_accuracy: 0.6410\n",
      "Epoch 146/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0612 - accuracy: 0.9803 - val_loss: 2.0012 - val_accuracy: 0.6667\n",
      "Epoch 147/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0616 - accuracy: 0.9737 - val_loss: 1.9685 - val_accuracy: 0.6667\n",
      "Epoch 148/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0599 - accuracy: 0.9737 - val_loss: 1.9716 - val_accuracy: 0.6667\n",
      "Epoch 149/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0725 - accuracy: 0.9737 - val_loss: 1.9797 - val_accuracy: 0.6667\n",
      "Epoch 150/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0659 - accuracy: 0.9868 - val_loss: 1.9944 - val_accuracy: 0.6667\n",
      "Epoch 151/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0594 - accuracy: 0.9803 - val_loss: 1.9907 - val_accuracy: 0.6667\n",
      "Epoch 152/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0745 - accuracy: 0.9803 - val_loss: 1.9699 - val_accuracy: 0.6667\n",
      "Epoch 153/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0621 - accuracy: 0.9737 - val_loss: 1.9742 - val_accuracy: 0.6410\n",
      "Epoch 154/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0643 - accuracy: 0.9868 - val_loss: 2.0142 - val_accuracy: 0.6154\n",
      "Epoch 155/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0558 - accuracy: 0.9868 - val_loss: 2.0283 - val_accuracy: 0.6154\n",
      "Epoch 156/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0562 - accuracy: 0.9803 - val_loss: 2.0411 - val_accuracy: 0.6410\n",
      "Epoch 157/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0696 - accuracy: 0.9671 - val_loss: 1.9992 - val_accuracy: 0.6410\n",
      "Epoch 158/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0560 - accuracy: 0.9803 - val_loss: 2.0077 - val_accuracy: 0.6410\n",
      "Epoch 159/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0847 - accuracy: 0.9737 - val_loss: 1.9914 - val_accuracy: 0.6410\n",
      "Epoch 160/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0714 - accuracy: 0.9803 - val_loss: 2.0105 - val_accuracy: 0.6410\n",
      "Epoch 161/400\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0687 - accuracy: 0.9803 - val_loss: 1.9944 - val_accuracy: 0.6667\n",
      "Epoch 162/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0841 - accuracy: 0.9737 - val_loss: 2.0038 - val_accuracy: 0.6410\n",
      "Epoch 163/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0574 - accuracy: 0.9868 - val_loss: 2.0331 - val_accuracy: 0.6410\n",
      "Epoch 164/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0456 - accuracy: 0.9868 - val_loss: 2.0353 - val_accuracy: 0.6410\n",
      "Epoch 165/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0551 - accuracy: 0.9737 - val_loss: 2.0235 - val_accuracy: 0.6410\n",
      "Epoch 166/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0450 - accuracy: 0.9803 - val_loss: 2.0166 - val_accuracy: 0.6410\n",
      "Epoch 167/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0743 - accuracy: 0.9737 - val_loss: 2.0203 - val_accuracy: 0.6410\n",
      "Epoch 168/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0725 - accuracy: 0.9737 - val_loss: 2.0438 - val_accuracy: 0.6410\n",
      "Epoch 169/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0528 - accuracy: 0.9803 - val_loss: 2.0499 - val_accuracy: 0.6410\n",
      "Epoch 170/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0550 - accuracy: 0.9868 - val_loss: 2.0783 - val_accuracy: 0.6410\n",
      "Epoch 171/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0773 - accuracy: 0.9803 - val_loss: 2.0737 - val_accuracy: 0.6410\n",
      "Epoch 172/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0773 - accuracy: 0.9671 - val_loss: 2.0409 - val_accuracy: 0.6410\n",
      "Epoch 173/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0545 - accuracy: 0.9803 - val_loss: 2.0084 - val_accuracy: 0.6667\n",
      "Epoch 174/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0927 - accuracy: 0.9803 - val_loss: 1.9944 - val_accuracy: 0.6667\n",
      "Epoch 175/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0557 - accuracy: 0.9868 - val_loss: 2.0016 - val_accuracy: 0.6667\n",
      "Epoch 176/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0755 - accuracy: 0.9671 - val_loss: 2.0124 - val_accuracy: 0.6667\n",
      "Epoch 177/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0675 - accuracy: 0.9737 - val_loss: 2.0243 - val_accuracy: 0.6667\n",
      "Epoch 178/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0628 - accuracy: 0.9803 - val_loss: 2.0276 - val_accuracy: 0.6667\n",
      "Epoch 179/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0620 - accuracy: 0.9737 - val_loss: 2.0208 - val_accuracy: 0.6667\n",
      "Epoch 180/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0523 - accuracy: 0.9803 - val_loss: 2.0325 - val_accuracy: 0.6667\n",
      "Epoch 181/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0670 - accuracy: 0.9803 - val_loss: 2.0306 - val_accuracy: 0.6667\n",
      "Epoch 182/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0710 - accuracy: 0.9737 - val_loss: 1.9953 - val_accuracy: 0.6667\n",
      "Epoch 183/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0766 - accuracy: 0.9737 - val_loss: 1.9798 - val_accuracy: 0.6667\n",
      "Epoch 184/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0660 - accuracy: 0.9737 - val_loss: 1.9987 - val_accuracy: 0.6667\n",
      "Epoch 185/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0513 - accuracy: 0.9737 - val_loss: 2.0496 - val_accuracy: 0.6410\n",
      "Epoch 186/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0676 - accuracy: 0.9737 - val_loss: 2.0532 - val_accuracy: 0.6410\n",
      "Epoch 187/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0717 - accuracy: 0.9671 - val_loss: 2.0379 - val_accuracy: 0.6410\n",
      "Epoch 188/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0538 - accuracy: 0.9737 - val_loss: 2.0985 - val_accuracy: 0.6154\n",
      "Epoch 189/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0778 - accuracy: 0.9671 - val_loss: 2.1439 - val_accuracy: 0.6154\n",
      "Epoch 190/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0725 - accuracy: 0.9803 - val_loss: 2.0900 - val_accuracy: 0.6410\n",
      "Epoch 191/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0576 - accuracy: 0.9737 - val_loss: 2.0463 - val_accuracy: 0.6410\n",
      "Epoch 192/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0603 - accuracy: 0.9803 - val_loss: 2.0347 - val_accuracy: 0.6667\n",
      "Epoch 193/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0923 - accuracy: 0.9671 - val_loss: 2.0004 - val_accuracy: 0.6667\n",
      "Epoch 194/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0783 - accuracy: 0.9737 - val_loss: 2.0096 - val_accuracy: 0.6410\n",
      "Epoch 195/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0641 - accuracy: 0.9737 - val_loss: 2.0016 - val_accuracy: 0.6410\n",
      "Epoch 196/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0673 - accuracy: 0.9803 - val_loss: 1.9919 - val_accuracy: 0.6410\n",
      "Epoch 197/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0771 - accuracy: 0.9803 - val_loss: 1.9793 - val_accuracy: 0.6667\n",
      "Epoch 198/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0479 - accuracy: 0.9803 - val_loss: 1.9971 - val_accuracy: 0.6667\n",
      "Epoch 199/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0858 - accuracy: 0.9737 - val_loss: 1.9926 - val_accuracy: 0.6667\n",
      "Epoch 200/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0666 - accuracy: 0.9803 - val_loss: 2.0208 - val_accuracy: 0.6410\n",
      "Epoch 201/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0711 - accuracy: 0.9737 - val_loss: 2.0402 - val_accuracy: 0.6410\n",
      "Epoch 202/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0818 - accuracy: 0.9737 - val_loss: 2.0493 - val_accuracy: 0.6410\n",
      "Epoch 203/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0518 - accuracy: 0.9737 - val_loss: 2.0346 - val_accuracy: 0.6410\n",
      "Epoch 204/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0674 - accuracy: 0.9803 - val_loss: 1.9961 - val_accuracy: 0.6410\n",
      "Epoch 205/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0793 - accuracy: 0.9803 - val_loss: 1.9843 - val_accuracy: 0.6410\n",
      "Epoch 206/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0585 - accuracy: 0.9737 - val_loss: 1.9869 - val_accuracy: 0.6410\n",
      "Epoch 207/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0588 - accuracy: 0.9803 - val_loss: 2.0089 - val_accuracy: 0.6410\n",
      "Epoch 208/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0752 - accuracy: 0.9671 - val_loss: 2.0020 - val_accuracy: 0.6410\n",
      "Epoch 209/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0742 - accuracy: 0.9737 - val_loss: 2.0164 - val_accuracy: 0.6410\n",
      "Epoch 210/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0605 - accuracy: 0.9803 - val_loss: 2.0229 - val_accuracy: 0.6410\n",
      "Epoch 211/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0723 - accuracy: 0.9737 - val_loss: 2.0373 - val_accuracy: 0.6410\n",
      "Epoch 212/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0695 - accuracy: 0.9737 - val_loss: 2.0371 - val_accuracy: 0.6410\n",
      "Epoch 213/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0639 - accuracy: 0.9803 - val_loss: 2.0609 - val_accuracy: 0.6410\n",
      "Epoch 214/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0433 - accuracy: 0.9737 - val_loss: 2.0694 - val_accuracy: 0.6410\n",
      "Epoch 215/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0656 - accuracy: 0.9803 - val_loss: 2.0485 - val_accuracy: 0.6410\n",
      "Epoch 216/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0527 - accuracy: 0.9803 - val_loss: 2.0408 - val_accuracy: 0.6410\n",
      "Epoch 217/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0665 - accuracy: 0.9737 - val_loss: 2.0313 - val_accuracy: 0.6410\n",
      "Epoch 218/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0493 - accuracy: 0.9803 - val_loss: 2.0195 - val_accuracy: 0.6410\n",
      "Epoch 219/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0462 - accuracy: 0.9803 - val_loss: 2.0139 - val_accuracy: 0.6410\n",
      "Epoch 220/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0673 - accuracy: 0.9803 - val_loss: 2.0427 - val_accuracy: 0.6410\n",
      "Epoch 221/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0460 - accuracy: 0.9868 - val_loss: 2.0471 - val_accuracy: 0.6410\n",
      "Epoch 222/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0727 - accuracy: 0.9605 - val_loss: 2.0592 - val_accuracy: 0.6410\n",
      "Epoch 223/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0735 - accuracy: 0.9737 - val_loss: 2.0619 - val_accuracy: 0.6410\n",
      "Epoch 224/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0486 - accuracy: 0.9868 - val_loss: 2.0520 - val_accuracy: 0.6410\n",
      "Epoch 225/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0879 - accuracy: 0.9671 - val_loss: 2.0620 - val_accuracy: 0.6410\n",
      "Epoch 226/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0580 - accuracy: 0.9803 - val_loss: 2.0700 - val_accuracy: 0.6410\n",
      "Epoch 227/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0587 - accuracy: 0.9803 - val_loss: 2.0391 - val_accuracy: 0.6410\n",
      "Epoch 228/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0624 - accuracy: 0.9737 - val_loss: 2.0042 - val_accuracy: 0.6410\n",
      "Epoch 229/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0698 - accuracy: 0.9737 - val_loss: 1.9810 - val_accuracy: 0.6410\n",
      "Epoch 230/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0704 - accuracy: 0.9803 - val_loss: 1.9805 - val_accuracy: 0.6410\n",
      "Epoch 231/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0531 - accuracy: 0.9868 - val_loss: 1.9765 - val_accuracy: 0.6410\n",
      "Epoch 232/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 0.9737 - val_loss: 1.9878 - val_accuracy: 0.6410\n",
      "Epoch 233/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0592 - accuracy: 0.9803 - val_loss: 1.9786 - val_accuracy: 0.6667\n",
      "Epoch 234/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0784 - accuracy: 0.9605 - val_loss: 1.9732 - val_accuracy: 0.6410\n",
      "Epoch 235/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0713 - accuracy: 0.9803 - val_loss: 2.0214 - val_accuracy: 0.6410\n",
      "Epoch 236/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0692 - accuracy: 0.9671 - val_loss: 2.0515 - val_accuracy: 0.6410\n",
      "Epoch 237/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0669 - accuracy: 0.9803 - val_loss: 2.0350 - val_accuracy: 0.6667\n",
      "Epoch 238/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0875 - accuracy: 0.9737 - val_loss: 2.0289 - val_accuracy: 0.6667\n",
      "Epoch 239/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0536 - accuracy: 0.9803 - val_loss: 2.0382 - val_accuracy: 0.6667\n",
      "Epoch 240/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0544 - accuracy: 0.9737 - val_loss: 2.0431 - val_accuracy: 0.6667\n",
      "Epoch 241/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0576 - accuracy: 0.9803 - val_loss: 2.0188 - val_accuracy: 0.6667\n",
      "Epoch 242/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0583 - accuracy: 0.9737 - val_loss: 2.0141 - val_accuracy: 0.6667\n",
      "Epoch 243/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0782 - accuracy: 0.9737 - val_loss: 2.0302 - val_accuracy: 0.6667\n",
      "Epoch 244/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0712 - accuracy: 0.9803 - val_loss: 1.9960 - val_accuracy: 0.6667\n",
      "Epoch 245/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0719 - accuracy: 0.9803 - val_loss: 1.9907 - val_accuracy: 0.6667\n",
      "Epoch 246/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.9737 - val_loss: 2.0491 - val_accuracy: 0.6410\n",
      "Epoch 247/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0578 - accuracy: 0.9803 - val_loss: 2.1244 - val_accuracy: 0.6410\n",
      "Epoch 248/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0714 - accuracy: 0.9737 - val_loss: 2.1299 - val_accuracy: 0.6410\n",
      "Epoch 249/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0619 - accuracy: 0.9803 - val_loss: 2.1124 - val_accuracy: 0.6410\n",
      "Epoch 250/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0605 - accuracy: 0.9737 - val_loss: 2.0927 - val_accuracy: 0.6410\n",
      "Epoch 251/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0631 - accuracy: 0.9803 - val_loss: 2.0639 - val_accuracy: 0.6410\n",
      "Epoch 252/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0768 - accuracy: 0.9737 - val_loss: 2.0594 - val_accuracy: 0.6667\n",
      "Epoch 253/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0611 - accuracy: 0.9737 - val_loss: 2.0727 - val_accuracy: 0.6410\n",
      "Epoch 254/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0592 - accuracy: 0.9737 - val_loss: 2.0707 - val_accuracy: 0.6410\n",
      "Epoch 255/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0561 - accuracy: 0.9803 - val_loss: 2.0779 - val_accuracy: 0.6410\n",
      "Epoch 256/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0633 - accuracy: 0.9803 - val_loss: 2.0703 - val_accuracy: 0.6410\n",
      "Epoch 257/400\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0557 - accuracy: 0.9803 - val_loss: 2.0856 - val_accuracy: 0.6667\n",
      "Epoch 258/400\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0546 - accuracy: 0.9803 - val_loss: 2.0857 - val_accuracy: 0.6667\n",
      "Epoch 259/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0484 - accuracy: 0.9671 - val_loss: 2.0876 - val_accuracy: 0.6667\n",
      "Epoch 260/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0726 - accuracy: 0.9803 - val_loss: 2.0924 - val_accuracy: 0.6410\n",
      "Epoch 261/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0694 - accuracy: 0.9737 - val_loss: 2.0955 - val_accuracy: 0.6410\n",
      "Epoch 262/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0661 - accuracy: 0.9737 - val_loss: 2.0962 - val_accuracy: 0.6410\n",
      "Epoch 263/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0604 - accuracy: 0.9803 - val_loss: 2.0752 - val_accuracy: 0.6410\n",
      "Epoch 264/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0589 - accuracy: 0.9803 - val_loss: 2.0684 - val_accuracy: 0.6667\n",
      "Epoch 265/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0558 - accuracy: 0.9803 - val_loss: 2.0621 - val_accuracy: 0.6667\n",
      "Epoch 266/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0666 - accuracy: 0.9737 - val_loss: 2.0589 - val_accuracy: 0.6667\n",
      "Epoch 267/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0627 - accuracy: 0.9737 - val_loss: 2.0508 - val_accuracy: 0.6667\n",
      "Epoch 268/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0527 - accuracy: 0.9737 - val_loss: 2.0599 - val_accuracy: 0.6667\n",
      "Epoch 269/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0603 - accuracy: 0.9737 - val_loss: 2.0521 - val_accuracy: 0.6667\n",
      "Epoch 270/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0597 - accuracy: 0.9803 - val_loss: 2.0999 - val_accuracy: 0.6410\n",
      "Epoch 271/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0714 - accuracy: 0.9671 - val_loss: 2.1169 - val_accuracy: 0.6410\n",
      "Epoch 272/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0680 - accuracy: 0.9803 - val_loss: 2.1521 - val_accuracy: 0.6410\n",
      "Epoch 273/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0581 - accuracy: 0.9803 - val_loss: 2.1571 - val_accuracy: 0.6410\n",
      "Epoch 274/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0662 - accuracy: 0.9737 - val_loss: 2.1528 - val_accuracy: 0.6667\n",
      "Epoch 275/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0547 - accuracy: 0.9803 - val_loss: 2.1514 - val_accuracy: 0.6410\n",
      "Epoch 276/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0529 - accuracy: 0.9737 - val_loss: 2.1244 - val_accuracy: 0.6410\n",
      "Epoch 277/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0580 - accuracy: 0.9803 - val_loss: 2.1153 - val_accuracy: 0.6410\n",
      "Epoch 278/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0623 - accuracy: 0.9737 - val_loss: 2.1063 - val_accuracy: 0.6410\n",
      "Epoch 279/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0538 - accuracy: 0.9737 - val_loss: 2.1253 - val_accuracy: 0.6410\n",
      "Epoch 280/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0477 - accuracy: 0.9803 - val_loss: 2.1446 - val_accuracy: 0.6410\n",
      "Epoch 281/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0622 - accuracy: 0.9803 - val_loss: 2.1441 - val_accuracy: 0.6410\n",
      "Epoch 282/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0406 - accuracy: 0.9803 - val_loss: 2.1257 - val_accuracy: 0.6410\n",
      "Epoch 283/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0659 - accuracy: 0.9737 - val_loss: 2.1260 - val_accuracy: 0.6410\n",
      "Epoch 284/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0608 - accuracy: 0.9803 - val_loss: 2.1354 - val_accuracy: 0.6410\n",
      "Epoch 285/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0603 - accuracy: 0.9737 - val_loss: 2.1655 - val_accuracy: 0.6410\n",
      "Epoch 286/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0756 - accuracy: 0.9803 - val_loss: 2.1998 - val_accuracy: 0.6410\n",
      "Epoch 287/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0588 - accuracy: 0.9803 - val_loss: 2.2191 - val_accuracy: 0.6410\n",
      "Epoch 288/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0634 - accuracy: 0.9737 - val_loss: 2.2200 - val_accuracy: 0.6410\n",
      "Epoch 289/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0636 - accuracy: 0.9803 - val_loss: 2.1770 - val_accuracy: 0.6410\n",
      "Epoch 290/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0629 - accuracy: 0.9803 - val_loss: 2.1511 - val_accuracy: 0.6410\n",
      "Epoch 291/400\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0583 - accuracy: 0.9803 - val_loss: 2.1435 - val_accuracy: 0.6410\n",
      "Epoch 292/400\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0655 - accuracy: 0.9803 - val_loss: 2.1447 - val_accuracy: 0.6410\n",
      "Epoch 293/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0583 - accuracy: 0.9737 - val_loss: 2.1347 - val_accuracy: 0.6410\n",
      "Epoch 294/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0711 - accuracy: 0.9671 - val_loss: 2.1305 - val_accuracy: 0.6410\n",
      "Epoch 295/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0678 - accuracy: 0.9671 - val_loss: 2.1532 - val_accuracy: 0.6410\n",
      "Epoch 296/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0704 - accuracy: 0.9803 - val_loss: 2.1570 - val_accuracy: 0.6410\n",
      "Epoch 297/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0579 - accuracy: 0.9803 - val_loss: 2.1805 - val_accuracy: 0.6410\n",
      "Epoch 298/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0493 - accuracy: 0.9803 - val_loss: 2.1815 - val_accuracy: 0.6410\n",
      "Epoch 299/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0627 - accuracy: 0.9737 - val_loss: 2.1820 - val_accuracy: 0.6410\n",
      "Epoch 300/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0585 - accuracy: 0.9803 - val_loss: 2.1685 - val_accuracy: 0.6410\n",
      "Epoch 301/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0546 - accuracy: 0.9737 - val_loss: 2.1822 - val_accuracy: 0.6410\n",
      "Epoch 302/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0458 - accuracy: 0.9803 - val_loss: 2.1873 - val_accuracy: 0.6410\n",
      "Epoch 303/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0578 - accuracy: 0.9803 - val_loss: 2.1995 - val_accuracy: 0.6410\n",
      "Epoch 304/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0594 - accuracy: 0.9803 - val_loss: 2.2194 - val_accuracy: 0.6410\n",
      "Epoch 305/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0542 - accuracy: 0.9803 - val_loss: 2.1948 - val_accuracy: 0.6410\n",
      "Epoch 306/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0567 - accuracy: 0.9803 - val_loss: 2.1353 - val_accuracy: 0.6410\n",
      "Epoch 307/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0597 - accuracy: 0.9868 - val_loss: 2.0833 - val_accuracy: 0.6410\n",
      "Epoch 308/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0635 - accuracy: 0.9671 - val_loss: 2.1304 - val_accuracy: 0.6410\n",
      "Epoch 309/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0609 - accuracy: 0.9737 - val_loss: 2.1673 - val_accuracy: 0.6410\n",
      "Epoch 310/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0514 - accuracy: 0.9737 - val_loss: 2.1891 - val_accuracy: 0.6410\n",
      "Epoch 311/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0488 - accuracy: 0.9803 - val_loss: 2.2048 - val_accuracy: 0.6410\n",
      "Epoch 312/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0659 - accuracy: 0.9803 - val_loss: 2.1883 - val_accuracy: 0.6410\n",
      "Epoch 313/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0748 - accuracy: 0.9737 - val_loss: 2.1625 - val_accuracy: 0.6410\n",
      "Epoch 314/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0533 - accuracy: 0.9803 - val_loss: 2.1475 - val_accuracy: 0.6410\n",
      "Epoch 315/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0474 - accuracy: 0.9803 - val_loss: 2.1376 - val_accuracy: 0.6410\n",
      "Epoch 316/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0521 - accuracy: 0.9803 - val_loss: 2.1417 - val_accuracy: 0.6410\n",
      "Epoch 317/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0522 - accuracy: 0.9868 - val_loss: 2.1410 - val_accuracy: 0.6410\n",
      "Epoch 318/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0629 - accuracy: 0.9803 - val_loss: 2.1309 - val_accuracy: 0.6410\n",
      "Epoch 319/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0673 - accuracy: 0.9737 - val_loss: 2.1393 - val_accuracy: 0.6410\n",
      "Epoch 320/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0452 - accuracy: 0.9803 - val_loss: 2.1372 - val_accuracy: 0.6410\n",
      "Epoch 321/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0748 - accuracy: 0.9803 - val_loss: 2.1486 - val_accuracy: 0.6410\n",
      "Epoch 322/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0535 - accuracy: 0.9803 - val_loss: 2.1539 - val_accuracy: 0.6410\n",
      "Epoch 323/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0550 - accuracy: 0.9803 - val_loss: 2.1708 - val_accuracy: 0.6410\n",
      "Epoch 324/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0603 - accuracy: 0.9803 - val_loss: 2.1771 - val_accuracy: 0.6410\n",
      "Epoch 325/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0481 - accuracy: 0.9803 - val_loss: 2.0831 - val_accuracy: 0.6410\n",
      "Epoch 326/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0632 - accuracy: 0.9671 - val_loss: 2.0799 - val_accuracy: 0.6410\n",
      "Epoch 327/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0494 - accuracy: 0.9803 - val_loss: 2.0919 - val_accuracy: 0.6410\n",
      "Epoch 328/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0623 - accuracy: 0.9803 - val_loss: 2.1064 - val_accuracy: 0.6410\n",
      "Epoch 329/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0638 - accuracy: 0.9803 - val_loss: 2.1748 - val_accuracy: 0.6410\n",
      "Epoch 330/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0601 - accuracy: 0.9803 - val_loss: 2.1943 - val_accuracy: 0.6410\n",
      "Epoch 331/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0605 - accuracy: 0.9737 - val_loss: 2.2031 - val_accuracy: 0.6410\n",
      "Epoch 332/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0551 - accuracy: 0.9803 - val_loss: 2.2002 - val_accuracy: 0.6410\n",
      "Epoch 333/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0566 - accuracy: 0.9803 - val_loss: 2.2121 - val_accuracy: 0.6410\n",
      "Epoch 334/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0596 - accuracy: 0.9737 - val_loss: 2.2192 - val_accuracy: 0.6410\n",
      "Epoch 335/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0485 - accuracy: 0.9803 - val_loss: 2.2144 - val_accuracy: 0.6410\n",
      "Epoch 336/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0444 - accuracy: 0.9803 - val_loss: 2.2001 - val_accuracy: 0.6410\n",
      "Epoch 337/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0647 - accuracy: 0.9803 - val_loss: 2.2031 - val_accuracy: 0.6410\n",
      "Epoch 338/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0551 - accuracy: 0.9803 - val_loss: 2.1962 - val_accuracy: 0.6410\n",
      "Epoch 339/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0635 - accuracy: 0.9803 - val_loss: 2.1785 - val_accuracy: 0.6410\n",
      "Epoch 340/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0577 - accuracy: 0.9737 - val_loss: 2.1629 - val_accuracy: 0.6410\n",
      "Epoch 341/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0490 - accuracy: 0.9803 - val_loss: 2.1522 - val_accuracy: 0.6410\n",
      "Epoch 342/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0626 - accuracy: 0.9803 - val_loss: 2.1327 - val_accuracy: 0.6410\n",
      "Epoch 343/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0552 - accuracy: 0.9868 - val_loss: 2.1383 - val_accuracy: 0.6410\n",
      "Epoch 344/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0541 - accuracy: 0.9803 - val_loss: 2.1369 - val_accuracy: 0.6410\n",
      "Epoch 345/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0568 - accuracy: 0.9737 - val_loss: 2.1179 - val_accuracy: 0.6410\n",
      "Epoch 346/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0520 - accuracy: 0.9803 - val_loss: 2.1415 - val_accuracy: 0.6410\n",
      "Epoch 347/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0592 - accuracy: 0.9803 - val_loss: 2.1881 - val_accuracy: 0.6410\n",
      "Epoch 348/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0461 - accuracy: 0.9868 - val_loss: 2.2151 - val_accuracy: 0.6410\n",
      "Epoch 349/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0482 - accuracy: 0.9803 - val_loss: 2.2128 - val_accuracy: 0.6410\n",
      "Epoch 350/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0605 - accuracy: 0.9737 - val_loss: 2.2022 - val_accuracy: 0.6410\n",
      "Epoch 351/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0642 - accuracy: 0.9737 - val_loss: 2.1962 - val_accuracy: 0.6410\n",
      "Epoch 352/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0575 - accuracy: 0.9803 - val_loss: 2.1934 - val_accuracy: 0.6410\n",
      "Epoch 353/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0632 - accuracy: 0.9803 - val_loss: 2.1861 - val_accuracy: 0.6410\n",
      "Epoch 354/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0584 - accuracy: 0.9803 - val_loss: 2.1903 - val_accuracy: 0.6410\n",
      "Epoch 355/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0558 - accuracy: 0.9803 - val_loss: 2.2063 - val_accuracy: 0.6410\n",
      "Epoch 356/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0723 - accuracy: 0.9803 - val_loss: 2.1932 - val_accuracy: 0.6410\n",
      "Epoch 357/400\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0649 - accuracy: 0.9605 - val_loss: 2.2134 - val_accuracy: 0.6410\n",
      "Epoch 358/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0523 - accuracy: 0.9868 - val_loss: 2.2320 - val_accuracy: 0.6410\n",
      "Epoch 359/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0582 - accuracy: 0.9803 - val_loss: 2.2567 - val_accuracy: 0.6410\n",
      "Epoch 360/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0634 - accuracy: 0.9737 - val_loss: 2.2603 - val_accuracy: 0.6410\n",
      "Epoch 361/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0483 - accuracy: 0.9803 - val_loss: 2.2266 - val_accuracy: 0.6410\n",
      "Epoch 362/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0534 - accuracy: 0.9737 - val_loss: 2.2088 - val_accuracy: 0.6410\n",
      "Epoch 363/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0529 - accuracy: 0.9803 - val_loss: 2.2065 - val_accuracy: 0.6410\n",
      "Epoch 364/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0532 - accuracy: 0.9868 - val_loss: 2.1835 - val_accuracy: 0.6410\n",
      "Epoch 365/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0601 - accuracy: 0.9803 - val_loss: 2.1935 - val_accuracy: 0.6410\n",
      "Epoch 366/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0625 - accuracy: 0.9737 - val_loss: 2.2166 - val_accuracy: 0.6410\n",
      "Epoch 367/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0697 - accuracy: 0.9737 - val_loss: 2.2360 - val_accuracy: 0.6410\n",
      "Epoch 368/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0491 - accuracy: 0.9737 - val_loss: 2.2533 - val_accuracy: 0.6410\n",
      "Epoch 369/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0440 - accuracy: 0.9803 - val_loss: 2.2631 - val_accuracy: 0.6410\n",
      "Epoch 370/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0619 - accuracy: 0.9803 - val_loss: 2.2665 - val_accuracy: 0.6410\n",
      "Epoch 371/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0631 - accuracy: 0.9737 - val_loss: 2.2534 - val_accuracy: 0.6410\n",
      "Epoch 372/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0489 - accuracy: 0.9803 - val_loss: 2.2633 - val_accuracy: 0.6410\n",
      "Epoch 373/400\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0566 - accuracy: 0.9803 - val_loss: 2.2815 - val_accuracy: 0.6154\n",
      "Epoch 374/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0707 - accuracy: 0.9803 - val_loss: 2.2740 - val_accuracy: 0.6154\n",
      "Epoch 375/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0545 - accuracy: 0.9737 - val_loss: 2.2548 - val_accuracy: 0.6410\n",
      "Epoch 376/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0567 - accuracy: 0.9803 - val_loss: 2.2529 - val_accuracy: 0.6410\n",
      "Epoch 377/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0536 - accuracy: 0.9803 - val_loss: 2.2246 - val_accuracy: 0.6410\n",
      "Epoch 378/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0599 - accuracy: 0.9803 - val_loss: 2.2167 - val_accuracy: 0.6410\n",
      "Epoch 379/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0622 - accuracy: 0.9737 - val_loss: 2.2194 - val_accuracy: 0.6410\n",
      "Epoch 380/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0528 - accuracy: 0.9737 - val_loss: 2.2336 - val_accuracy: 0.6410\n",
      "Epoch 381/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0598 - accuracy: 0.9737 - val_loss: 2.2588 - val_accuracy: 0.6410\n",
      "Epoch 382/400\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0602 - accuracy: 0.9737 - val_loss: 2.2818 - val_accuracy: 0.6410\n",
      "Epoch 383/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0587 - accuracy: 0.9803 - val_loss: 2.2464 - val_accuracy: 0.6410\n",
      "Epoch 384/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0524 - accuracy: 0.9803 - val_loss: 2.2392 - val_accuracy: 0.6410\n",
      "Epoch 385/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0463 - accuracy: 0.9803 - val_loss: 2.2458 - val_accuracy: 0.6410\n",
      "Epoch 386/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0575 - accuracy: 0.9803 - val_loss: 2.2574 - val_accuracy: 0.6410\n",
      "Epoch 387/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0538 - accuracy: 0.9803 - val_loss: 2.2688 - val_accuracy: 0.6410\n",
      "Epoch 388/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0538 - accuracy: 0.9803 - val_loss: 2.2816 - val_accuracy: 0.6410\n",
      "Epoch 389/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0594 - accuracy: 0.9803 - val_loss: 2.3024 - val_accuracy: 0.6410\n",
      "Epoch 390/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0495 - accuracy: 0.9803 - val_loss: 2.2899 - val_accuracy: 0.6410\n",
      "Epoch 391/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0638 - accuracy: 0.9803 - val_loss: 2.2815 - val_accuracy: 0.6410\n",
      "Epoch 392/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0590 - accuracy: 0.9737 - val_loss: 2.2634 - val_accuracy: 0.6410\n",
      "Epoch 393/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0436 - accuracy: 0.9803 - val_loss: 2.2737 - val_accuracy: 0.6410\n",
      "Epoch 394/400\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0571 - accuracy: 0.9803 - val_loss: 2.2767 - val_accuracy: 0.6410\n",
      "Epoch 395/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0613 - accuracy: 0.9737 - val_loss: 2.2863 - val_accuracy: 0.6410\n",
      "Epoch 396/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0616 - accuracy: 0.9737 - val_loss: 2.2896 - val_accuracy: 0.6410\n",
      "Epoch 397/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0591 - accuracy: 0.9803 - val_loss: 2.2889 - val_accuracy: 0.6410\n",
      "Epoch 398/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0546 - accuracy: 0.9803 - val_loss: 2.2690 - val_accuracy: 0.6410\n",
      "Epoch 399/400\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0476 - accuracy: 0.9803 - val_loss: 2.2634 - val_accuracy: 0.6410\n",
      "Epoch 400/400\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0524 - accuracy: 0.9803 - val_loss: 2.2700 - val_accuracy: 0.6410\n",
      "CPU times: total: 1min 2s\n",
      "Wall time: 46.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "EPOCH = 400\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "history_LSTM = model_LSTM.fit(X_train, y_train, epochs=EPOCH, batch_size=BATCH_SIZE, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...   0  20   1]\n",
      " [  0   0   0 ...   0   1  20]\n",
      " [  0   0   0 ...   0   2   6]\n",
      " ...\n",
      " [  0   0   4 ...  17   1  56]\n",
      " [  0   0   0 ...  90 142  42]\n",
      " [  0   4  92 ...  17   1  76]]\n"
     ]
    }
   ],
   "source": [
    "# Apply padding \n",
    "x_train = pad_sequences(train)\n",
    "print(x_train) # Padding Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# input length\n",
    "input_shape = x_train.shape[1]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words :  142\n",
      "output length:  30\n"
     ]
    }
   ],
   "source": [
    "# define vocabulary\n",
    "vocabulary = len(tokenizer.word_index)\n",
    "print(\"number of unique words : \", vocabulary)\n",
    "\n",
    "# output length\n",
    "output_length = le.classes_.shape[0]\n",
    "print(\"output length: \", output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kamu': 1, 'ini': 2, 'wardas': 3, 'berapa': 4, 'cepat': 5, 'apa': 6, 'saya': 7, 'jadi': 8, 'robot': 9, 'sekarang': 10, 'beritahu': 11, 'dapat': 12, 'dengan': 13, 'mana': 14, 'selamat': 15, 'hari': 16, 'yang': 17, 'baik': 18, 'saat': 19, 'siapa': 20, 'tanggal': 21, 'bebanberat': 22, 'bawa': 23, 'apakah': 24, 'kapan': 25, 'jawab': 26, 'lagi': 27, 'bantu': 28, 'ruang': 29, 'ubah': 30, 'lambat': 31, 'tidak': 32, 'salah': 33, 'hobi': 34, 'halo': 35, 'siang': 36, 'pagi': 37, 'sore': 38, 'malam': 39, 'suhu': 40, 'lembap': 41, 'baterai': 42, 'untuk': 43, 'diri': 44, 'tentang': 45, 'bicara': 46, 'cipta': 47, 'buat': 48, 'benar': 49, 'lebih': 50, 'siap': 51, 'sedangmedium': 52, 'guna': 53, 'itu': 54, 'ada': 55, 'milik': 56, 'butuh': 57, 'ayo': 58, 'terimakasih': 59, 'jam': 60, 'saja': 61, 'kata': 62, 'anda': 63, 'cerita': 64, 'umur': 65, 'usia': 66, 'bodoh': 67, 'tanya': 68, 'sampai': 69, 'pintar': 70, 'moga': 71, 'pintarbaik': 72, 'harus': 73, 'ajar': 74, 'kembang': 75, 'punya': 76, 'sudah': 77, 'asal': 78, 'masalah': 79, 'lokasi': 80, 'tunjuk': 81, 'mu': 82, 'pada': 83, 'terima': 84, 'kasih': 85, 'banyak': 86, 'dulu': 87, 'waktu': 88, 'hingga': 89, 'jumlah': 90, 'daya': 91, 'persen': 92, 'fungsi': 93, 'jelas': 94, 'beritahukan': 95, 'tidakkurang': 96, 'kenapa': 97, 'respon': 98, 'merespon': 99, 'agar': 100, 'coba': 101, 'rubah': 102, 'pemilikmupengembangmubosmu': 103, 'oleh': 104, 'bisa': 105, 'ku': 106, 'bagaimana': 107, 'ready': 108, 'darimana': 109, 'dari': 110, 'benarpintar': 111, 'dalam': 112, 'hebat': 113, 'obrol': 114, 'ngobrol': 115, 'yu': 116, 'haiiii': 117, 'haloooo': 118, 'hello': 119, 'hai': 120, 'yoo': 121, 'kabar': 122, 'sangat': 123, 'ikan': 124, 'sedang': 125, 'thank': 126, 'tengkyu': 127, 'atas': 128, 'tinggal': 129, 'dadah': 130, 'jumpa': 131, 'pergi': 132, 'ya': 133, 'cabut': 134, 'pukul': 135, 'mau': 136, 'maksimal': 137, 'kuat': 138, 'sedangmediumkan': 139, 'sedangmediumlah': 140, 'nilai': 141, 'kapasitas': 142}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model (Membuat Modeling)\n",
    "i = Input(shape=(input_shape,))\n",
    "x = Embedding(vocabulary+1,50)(i) # Layer Embedding\n",
    "x = LSTM(50, return_sequences=True)(x) # Layer Long Short Term Memory\n",
    "x = Flatten()(x) # Layer Flatten\n",
    "x = Dense(output_length, activation=\"softmax\")(x) # Layer Dense\n",
    "model  = Model(i,x)\n",
    "\n",
    "# Compiling the model (Kompilasi Model)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# Visualization Plot Architecture Model (Visualisasi Plot Arsitektur Model)\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 8, 50)             7150      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 8, 50)             20200     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                12030     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,380\n",
      "Trainable params: 39,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan Parameter Model\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 3s 109ms/step - loss: 3.3988 - accuracy: 0.0280 - val_loss: 3.4183 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.3807 - accuracy: 0.1119 - val_loss: 3.4501 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3.3561 - accuracy: 0.1119 - val_loss: 3.5087 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.3225 - accuracy: 0.1189 - val_loss: 3.6214 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.2700 - accuracy: 0.1049 - val_loss: 3.8445 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.1927 - accuracy: 0.1049 - val_loss: 4.2890 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1202 - accuracy: 0.1049 - val_loss: 5.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.0854 - accuracy: 0.1049 - val_loss: 5.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0682 - accuracy: 0.1049 - val_loss: 5.7665 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.0265 - accuracy: 0.1189 - val_loss: 5.9596 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0019 - accuracy: 0.1189 - val_loss: 6.1946 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.9733 - accuracy: 0.1259 - val_loss: 6.5680 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.9419 - accuracy: 0.1329 - val_loss: 6.7299 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.9005 - accuracy: 0.1469 - val_loss: 7.1228 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.8527 - accuracy: 0.1678 - val_loss: 7.6130 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.7870 - accuracy: 0.1608 - val_loss: 7.9713 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.7065 - accuracy: 0.2028 - val_loss: 8.5070 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.6150 - accuracy: 0.2657 - val_loss: 9.0939 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.5189 - accuracy: 0.2098 - val_loss: 9.4330 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.4014 - accuracy: 0.3007 - val_loss: 9.8349 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.3124 - accuracy: 0.3287 - val_loss: 10.4327 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.2101 - accuracy: 0.3147 - val_loss: 10.5558 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.1075 - accuracy: 0.4406 - val_loss: 11.3266 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.0245 - accuracy: 0.4615 - val_loss: 11.6511 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.9283 - accuracy: 0.4755 - val_loss: 11.5549 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8741 - accuracy: 0.5594 - val_loss: 11.5541 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7801 - accuracy: 0.5594 - val_loss: 11.9635 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7092 - accuracy: 0.6154 - val_loss: 12.1694 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6267 - accuracy: 0.6294 - val_loss: 11.9260 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5604 - accuracy: 0.6294 - val_loss: 11.9788 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4942 - accuracy: 0.6364 - val_loss: 12.4504 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4231 - accuracy: 0.6853 - val_loss: 12.0296 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3871 - accuracy: 0.6923 - val_loss: 12.5015 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3173 - accuracy: 0.6783 - val_loss: 12.1183 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2460 - accuracy: 0.8042 - val_loss: 12.3630 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1798 - accuracy: 0.8252 - val_loss: 12.4701 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1242 - accuracy: 0.8671 - val_loss: 12.4714 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0710 - accuracy: 0.8392 - val_loss: 12.5686 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0287 - accuracy: 0.8671 - val_loss: 12.7902 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.9855 - accuracy: 0.8881 - val_loss: 12.6881 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.9288 - accuracy: 0.8881 - val_loss: 12.7176 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.8896 - accuracy: 0.8811 - val_loss: 12.7840 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8482 - accuracy: 0.9091 - val_loss: 12.8340 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8132 - accuracy: 0.8881 - val_loss: 12.9010 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7798 - accuracy: 0.9161 - val_loss: 13.0075 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7413 - accuracy: 0.9161 - val_loss: 13.1775 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7060 - accuracy: 0.9231 - val_loss: 13.0453 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6828 - accuracy: 0.9371 - val_loss: 13.1598 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6511 - accuracy: 0.9231 - val_loss: 13.1967 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6298 - accuracy: 0.9441 - val_loss: 13.0364 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Training the model (Latih model data sampai 400 kali)\n",
    "train = model.fit(x_train, y_train, epochs=50, validation_split = 0.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bb2665b6143e7d2b1179771d9cc5a88bd139c21d8991d9a3851b853d0d9eb90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
